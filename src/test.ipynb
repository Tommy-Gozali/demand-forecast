{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.datasets import fetch_dataset\n",
    "data = fetch_dataset(name='h2o_exog', raw=True, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df = px.data.gapminder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'continent',\n",
       " 'year',\n",
       " 'lifeExp',\n",
       " 'pop',\n",
       " 'gdpPercap',\n",
       " 'iso_alpha',\n",
       " 'iso_num',\n",
       " 'test']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns.values) + [\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_test = pd.read_csv('data_test.csv').set_index(\"Datetime\").sort_index()\n",
    "data_test.index = pd.to_datetime(data_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "cwd = os.path.abspath(\"\")\n",
    "modelling_file_path = os.path.join(cwd, './modelling/model/forecaster.joblib')\n",
    "\n",
    "forecaster = joblib.load(modelling_file_path)\n",
    "regressor_name = str(forecaster.regressor).split('()')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog_vars = ['month', 'dayofweek', 'hour', 'temperature_2m', \n",
    "             'relative_humidity_2m', 'dew_point_2m', 'apparent_temperature', \n",
    "             'is_day', 'temperature_2m_rolling_mean_1_D', 'temperature_2m_rolling_max_1_D', \n",
    "             'temperature_2m_rolling_min_1_D', 'temperature_2m_rolling_mean_7_D', \n",
    "             'temperature_2m_rolling_max_7_D', 'temperature_2m_rolling_min_7_D']\n",
    "steps = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-03-26 00:00:00+00:00', '2023-03-26 01:00:00+00:00',\n",
       "               '2023-03-26 02:00:00+00:00', '2023-03-26 03:00:00+00:00',\n",
       "               '2023-03-26 04:00:00+00:00', '2023-03-26 05:00:00+00:00',\n",
       "               '2023-03-26 06:00:00+00:00', '2023-03-26 07:00:00+00:00',\n",
       "               '2023-03-26 08:00:00+00:00', '2023-03-26 09:00:00+00:00',\n",
       "               ...\n",
       "               '2023-06-23 14:00:00+00:00', '2023-06-23 15:00:00+00:00',\n",
       "               '2023-06-23 16:00:00+00:00', '2023-06-23 17:00:00+00:00',\n",
       "               '2023-06-23 18:00:00+00:00', '2023-06-23 19:00:00+00:00',\n",
       "               '2023-06-23 20:00:00+00:00', '2023-06-23 21:00:00+00:00',\n",
       "               '2023-06-23 22:00:00+00:00', '2023-06-23 23:00:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', name='Datetime', length=2160, freq=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[exog_vars].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2023-03-26 00:00:00+00:00', '2023-03-26 01:00:00+00:00',\n",
       "               '2023-03-26 02:00:00+00:00', '2023-03-26 03:00:00+00:00',\n",
       "               '2023-03-26 04:00:00+00:00', '2023-03-26 05:00:00+00:00',\n",
       "               '2023-03-26 06:00:00+00:00', '2023-03-26 07:00:00+00:00',\n",
       "               '2023-03-26 08:00:00+00:00', '2023-03-26 09:00:00+00:00',\n",
       "               ...\n",
       "               '2023-06-23 14:00:00+00:00', '2023-06-23 15:00:00+00:00',\n",
       "               '2023-06-23 16:00:00+00:00', '2023-06-23 17:00:00+00:00',\n",
       "               '2023-06-23 18:00:00+00:00', '2023-06-23 19:00:00+00:00',\n",
       "               '2023-06-23 20:00:00+00:00', '2023-06-23 21:00:00+00:00',\n",
       "               '2023-06-23 22:00:00+00:00', '2023-06-23 23:00:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', name='Datetime', length=2160, freq=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test[exog_vars].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alfon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\skforecast\\utils\\utils.py:1182: UserWarning: `exog` has DatetimeIndex index but no frequency. Index is overwritten with a RangeIndex of step 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected index of type <class 'pandas.core.indexes.datetimes.DatetimeIndex'> for `exog`. Got <class 'pandas.core.indexes.range.RangeIndex'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mforecaster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexog_vars\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alfon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\skforecast\\ForecasterAutoreg\\ForecasterAutoreg.py:767\u001b[0m, in \u001b[0;36mForecasterAutoreg.predict\u001b[1;34m(self, steps, last_window, exog)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_window \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m     last_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_window\n\u001b[1;32m--> 767\u001b[0m \u001b[43mcheck_predict_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforecaster_name\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mincluded_exog\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincluded_exog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_type\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_freq\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_size_diff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlast_window_exog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog_type\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexog_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexog_col_names\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexog_col_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterval\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseries_col_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    787\u001b[0m last_window \u001b[38;5;241m=\u001b[39m last_window\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size_diff:]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exog \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\alfon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\skforecast\\utils\\utils.py:917\u001b[0m, in \u001b[0;36mcheck_predict_input\u001b[1;34m(forecaster_name, steps, fitted, included_exog, index_type, index_freq, window_size, last_window, last_window_exog, exog, exog_type, exog_col_names, interval, alpha, max_steps, levels, levels_forecaster, series_col_names)\u001b[0m\n\u001b[0;32m    912\u001b[0m _, exog_index \u001b[38;5;241m=\u001b[39m preprocess_exog(\n\u001b[0;32m    913\u001b[0m                     exog          \u001b[38;5;241m=\u001b[39m exog_to_check\u001b[38;5;241m.\u001b[39miloc[:\u001b[38;5;241m0\u001b[39m, ],\n\u001b[0;32m    914\u001b[0m                     return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    915\u001b[0m                 )\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exog_index, index_type):\n\u001b[1;32m--> 917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected index of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexog_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    919\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(exog_index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    920\u001b[0m     )\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m forecaster_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForecasterAutoregMultiSeries\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m    922\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForecasterAutoregMultiSeriesCustom\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exog_index, pd\u001b[38;5;241m.\u001b[39mDatetimeIndex):\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected index of type <class 'pandas.core.indexes.datetimes.DatetimeIndex'> for `exog`. Got <class 'pandas.core.indexes.range.RangeIndex'>."
     ]
    }
   ],
   "source": [
    "predictions = forecaster.predict(steps = steps,\n",
    "                                exog  = data_test[exog_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from copy import deepcopy\n",
    "from utils import DataCleaningService, FeatureEngineering\n",
    "from create_experiment import CreateExperiment\n",
    "from get_exog_data import OpenMeteoApi\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "cwd = os.path.abspath(\"\")\n",
    "raw_data_file_path = os.path.join(cwd, '../data/power_load_BE_elia_15M_2015_2024.csv')\n",
    "df = pd.read_csv(raw_data_file_path, delimiter = \";\", on_bad_lines=\"skip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Tommy\\Work\\Scripting\\Portfolio\\demand-forecast\\src\\./modelling/model/forecaster.joblib\n"
     ]
    }
   ],
   "source": [
    "cwd = os.path.abspath(\"\")\n",
    "modelling_file_path = os.path.join(cwd, './modelling/model/forecaster.joblib')\n",
    "print(modelling_file_path)\n",
    "with open(modelling_file_path, 'w') as file:\n",
    "    file.write(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_start_date = \"2021-11-01\"\n",
    "clean_end_date   = \"2023-06-23\"\n",
    "hour_in_week     = 24*7\n",
    "\n",
    "# CLEAN INPUT DATA\n",
    "cleaning_service = DataCleaningService()\n",
    "df_clean = cleaning_service.normalize_to_timeseries_df(df = df,\n",
    "                                          start_date = clean_start_date,\n",
    "                                          end_date   = clean_end_date,\n",
    "                                          date_index = \"Datetime\",)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Datetime', 'Datetime', 'Resolution code']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_index = \"Datetime\"\n",
    "non_float_int_columns = [\"Datetime\", \"Resolution code\"]\n",
    "[date_index] + non_float_int_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alfon\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Load\n",
      "Most recent forecast\n",
      "Most recent P10\n",
      "Most recent P90\n",
      "Day-ahead 6PM forecast\n",
      "Day-ahead 6PM P10\n",
      "Day-ahead 6PM P90\n",
      "Week-ahead forecast\n",
      "Train dates : 2022-05-25 00:00:00+00:00 --- 2023-04-20 23:00:00+00:00  (n=7944)\n",
      "Test dates  : 2023-04-21 00:00:00+00:00 --- 2023-06-15 23:00:00+00:00  (n=1344)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from data_processing import steps, data, data_train, data_test, exog_vars, hour_in_week\n",
    "\n",
    "cwd = os.path.abspath(\"\")\n",
    "backtest_result_file_path = os.path.join(cwd, '../data/backtest_result.csv')\n",
    "\n",
    "df = pd.read_csv(backtest_result_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "modelling_file_path = os.path.join(cwd, './modelling/model/forecaster.joblib')\n",
    "backtest_result_file_path = os.path.join(cwd, '../data/backtest_result.csv')\n",
    "\n",
    "forecaster = joblib.load(modelling_file_path)\n",
    "regressor_name = str(forecaster.regressor).split('()')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast import BacktestingForecaster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 7776\n",
      "Number of observations used for backtesting: 1344\n",
      "    Number of folds: 8\n",
      "    Number of steps per fold: 168\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2022-06-01 00:00:00+00:00 -- 2023-04-20 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-04-21 00:00:00+00:00 -- 2023-04-27 23:00:00+00:00  (n=168)\n",
      "Fold: 1\n",
      "    Training:   2022-06-08 00:00:00+00:00 -- 2023-04-27 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-04-28 00:00:00+00:00 -- 2023-05-04 23:00:00+00:00  (n=168)\n",
      "Fold: 2\n",
      "    Training:   2022-06-15 00:00:00+00:00 -- 2023-05-04 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-05-05 00:00:00+00:00 -- 2023-05-11 23:00:00+00:00  (n=168)\n",
      "Fold: 3\n",
      "    Training:   2022-06-22 00:00:00+00:00 -- 2023-05-11 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-05-12 00:00:00+00:00 -- 2023-05-18 23:00:00+00:00  (n=168)\n",
      "Fold: 4\n",
      "    Training:   2022-06-29 00:00:00+00:00 -- 2023-05-18 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-05-19 00:00:00+00:00 -- 2023-05-25 23:00:00+00:00  (n=168)\n",
      "Fold: 5\n",
      "    Training:   2022-07-06 00:00:00+00:00 -- 2023-05-25 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-05-26 00:00:00+00:00 -- 2023-06-01 23:00:00+00:00  (n=168)\n",
      "Fold: 6\n",
      "    Training:   2022-07-13 00:00:00+00:00 -- 2023-06-01 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-06-02 00:00:00+00:00 -- 2023-06-08 23:00:00+00:00  (n=168)\n",
      "Fold: 7\n",
      "    Training:   2022-07-20 00:00:00+00:00 -- 2023-06-08 23:00:00+00:00  (n=7776)\n",
      "    Validation: 2023-06-09 00:00:00+00:00 -- 2023-06-15 23:00:00+00:00  (n=168)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bf = BacktestingForecaster(forecaster         = forecaster,\n",
    "                          y                  = data['y'],\n",
    "                          steps              = hour_in_week,\n",
    "                          metric             = 'mean_absolute_percentage_error',\n",
    "                          initial_train_size = len(data_train),\n",
    "                          refit              = True,)\n",
    "backtest_indexes = bf._create_backtesting_folds()\n",
    "\n",
    "backtesting_folds_list = bf.get_backtesting_folds(backtest_indexes = backtest_indexes,\n",
    "                         backtest_result_df = df,\n",
    "                         regressor_name= regressor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>RandomForestRegressor(max_depth=10, n_estimators=50)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [y, RandomForestRegressor(max_depth=10, n_estimators=50)]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backtesting_folds_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 108\n",
      "    Number of folds: 11\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 8 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   1991-07-01 00:00:00 -- 1999-06-01 00:00:00  (n=96)\n",
      "    Validation: 1999-07-01 00:00:00 -- 2000-04-01 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   1992-05-01 00:00:00 -- 2000-04-01 00:00:00  (n=96)\n",
      "    Validation: 2000-05-01 00:00:00 -- 2001-02-01 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   1993-03-01 00:00:00 -- 2001-02-01 00:00:00  (n=96)\n",
      "    Validation: 2001-03-01 00:00:00 -- 2001-12-01 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   1994-01-01 00:00:00 -- 2001-12-01 00:00:00  (n=96)\n",
      "    Validation: 2002-01-01 00:00:00 -- 2002-10-01 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   1994-11-01 00:00:00 -- 2002-10-01 00:00:00  (n=96)\n",
      "    Validation: 2002-11-01 00:00:00 -- 2003-08-01 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   1995-09-01 00:00:00 -- 2003-08-01 00:00:00  (n=96)\n",
      "    Validation: 2003-09-01 00:00:00 -- 2004-06-01 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   1996-07-01 00:00:00 -- 2004-06-01 00:00:00  (n=96)\n",
      "    Validation: 2004-07-01 00:00:00 -- 2005-04-01 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   1997-05-01 00:00:00 -- 2005-04-01 00:00:00  (n=96)\n",
      "    Validation: 2005-05-01 00:00:00 -- 2006-02-01 00:00:00  (n=10)\n",
      "Fold: 8\n",
      "    Training:   1998-03-01 00:00:00 -- 2006-02-01 00:00:00  (n=96)\n",
      "    Validation: 2006-03-01 00:00:00 -- 2006-12-01 00:00:00  (n=10)\n",
      "Fold: 9\n",
      "    Training:   1999-01-01 00:00:00 -- 2006-12-01 00:00:00  (n=96)\n",
      "    Validation: 2007-01-01 00:00:00 -- 2007-10-01 00:00:00  (n=10)\n",
      "Fold: 10\n",
      "    Training:   1999-11-01 00:00:00 -- 2007-10-01 00:00:00  (n=96)\n",
      "    Validation: 2007-11-01 00:00:00 -- 2008-06-01 00:00:00  (n=8)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 274.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds: 108\n",
      "Fold 0: pred\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load your data\n",
    "url = 'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv'\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "\n",
    "# Split data into training and backtesting sets\n",
    "n_backtest = 36 * 3  # Last 9 years for backtesting\n",
    "data_train = data[:-n_backtest]\n",
    "data_backtest = data[-n_backtest:]\n",
    "\n",
    "# Initialize the forecaster\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=RandomForestRegressor(random_state=123),\n",
    "    lags=15\n",
    ")\n",
    "\n",
    "# Perform backtesting\n",
    "metric, predictions_backtest = backtesting_forecaster(\n",
    "    forecaster=forecaster,\n",
    "    y=data['y'],\n",
    "    initial_train_size=len(data_train),\n",
    "    steps=10,\n",
    "    metric='mean_squared_error',\n",
    "    refit=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Print fold information\n",
    "print(f\"Number of folds: {len(predictions_backtest)}\")\n",
    "for i, fold in enumerate(predictions_backtest):\n",
    "    print(f\"Fold {i}: {fold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'if' statement on line 53 (forecast.py, line 54)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:3553\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 5\u001b[1;36m\n\u001b[1;33m    from forecast import BacktestingForecaster\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32mc:\\Tommy\\Work\\Scripting\\Portfolio\\demand-forecast\\src\\forecast.py:54\u001b[1;36m\u001b[0m\n\u001b[1;33m    data = pd.Series(index=data)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'if' statement on line 53\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from forecast import BacktestingForecaster\n",
    "\n",
    "# Load your data\n",
    "url = 'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv'\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "\n",
    "# Split data into training and backtesting sets\n",
    "n_backtest = 36 * 3  # Last 9 years for backtesting\n",
    "data_train = data[:-n_backtest]\n",
    "data_backtest = data[-n_backtest:]\n",
    "\n",
    "# Initialize the forecaster\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=RandomForestRegressor(random_state=123),\n",
    "    lags=15\n",
    ")\n",
    "bf = BacktestingForecaster(\n",
    "    forecaster=forecaster,\n",
    "    y=data['y'],\n",
    "    initial_train_size=len(data_train),\n",
    "    steps=10,\n",
    "    metric='mean_squared_error',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_training_index, fold_validation_index = bf._create_backtesting_folds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Timestamp('1999-07-01 00:00:00'), Timestamp('1999-07-01 00:00:00')],\n",
       " [Timestamp('2000-05-01 00:00:00'), Timestamp('2000-05-01 00:00:00')],\n",
       " [Timestamp('2001-03-01 00:00:00'), Timestamp('2001-03-01 00:00:00')],\n",
       " [Timestamp('2002-01-01 00:00:00'), Timestamp('2002-01-01 00:00:00')],\n",
       " [Timestamp('2002-11-01 00:00:00'), Timestamp('2002-11-01 00:00:00')],\n",
       " [Timestamp('2003-09-01 00:00:00'), Timestamp('2003-09-01 00:00:00')],\n",
       " [Timestamp('2004-07-01 00:00:00'), Timestamp('2004-07-01 00:00:00')],\n",
       " [Timestamp('2005-05-01 00:00:00'), Timestamp('2005-05-01 00:00:00')],\n",
       " [Timestamp('2006-03-01 00:00:00'), Timestamp('2006-03-01 00:00:00')],\n",
       " [Timestamp('2007-01-01 00:00:00'), Timestamp('2007-01-01 00:00:00')],\n",
       " [Timestamp('2007-11-01 00:00:00'), Timestamp('2007-11-01 00:00:00')]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_validation_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 108\n",
      "    Number of folds: 11\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 8 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   1991-07-01 00:00:00 -- 1999-06-01 00:00:00  (n=96)\n",
      "    Validation: 1999-07-01 00:00:00 -- 2000-04-01 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   1992-05-01 00:00:00 -- 2000-04-01 00:00:00  (n=96)\n",
      "    Validation: 2000-05-01 00:00:00 -- 2001-02-01 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   1993-03-01 00:00:00 -- 2001-02-01 00:00:00  (n=96)\n",
      "    Validation: 2001-03-01 00:00:00 -- 2001-12-01 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   1994-01-01 00:00:00 -- 2001-12-01 00:00:00  (n=96)\n",
      "    Validation: 2002-01-01 00:00:00 -- 2002-10-01 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   1994-11-01 00:00:00 -- 2002-10-01 00:00:00  (n=96)\n",
      "    Validation: 2002-11-01 00:00:00 -- 2003-08-01 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   1995-09-01 00:00:00 -- 2003-08-01 00:00:00  (n=96)\n",
      "    Validation: 2003-09-01 00:00:00 -- 2004-06-01 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   1996-07-01 00:00:00 -- 2004-06-01 00:00:00  (n=96)\n",
      "    Validation: 2004-07-01 00:00:00 -- 2005-04-01 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   1997-05-01 00:00:00 -- 2005-04-01 00:00:00  (n=96)\n",
      "    Validation: 2005-05-01 00:00:00 -- 2006-02-01 00:00:00  (n=10)\n",
      "Fold: 8\n",
      "    Training:   1998-03-01 00:00:00 -- 2006-02-01 00:00:00  (n=96)\n",
      "    Validation: 2006-03-01 00:00:00 -- 2006-12-01 00:00:00  (n=10)\n",
      "Fold: 9\n",
      "    Training:   1999-01-01 00:00:00 -- 2006-12-01 00:00:00  (n=96)\n",
      "    Validation: 2007-01-01 00:00:00 -- 2007-10-01 00:00:00  (n=10)\n",
      "Fold: 10\n",
      "    Training:   1999-11-01 00:00:00 -- 2007-10-01 00:00:00  (n=96)\n",
      "    Validation: 2007-11-01 00:00:00 -- 2008-06-01 00:00:00  (n=8)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 300.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# Perform backtesting\n",
    "metric, predictions_backtest = backtesting_forecaster(\n",
    "    forecaster=forecaster,\n",
    "    y=data['y'],\n",
    "    initial_train_size=len(data_train),\n",
    "    steps=10,\n",
    "    metric='mean_squared_error',\n",
    "    refit=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   folds = _create_backtesting_folds(\\n                data                  = y,\\n                window_size           = window_size,\\n                initial_train_size    = initial_train_size,\\n                test_size             = steps,\\n                externally_fitted     = externally_fitted,\\n                refit                 = refit,\\n                fixed_train_size      = fixed_train_size,\\n                gap                   = gap,\\n                skip_folds            = skip_folds,\\n                allow_incomplete_fold = allow_incomplete_fold,\\n                return_all_indexes    = False,\\n                differentiation       = differentiation,\\n                verbose               = verbose\\n\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "   folds = _create_backtesting_folds(\n",
    "                data                  = y,\n",
    "                window_size           = window_size,\n",
    "                initial_train_size    = initial_train_size,\n",
    "                test_size             = steps,\n",
    "                externally_fitted     = externally_fitted,\n",
    "                refit                 = refit,\n",
    "                fixed_train_size      = fixed_train_size,\n",
    "                gap                   = gap,\n",
    "                skip_folds            = skip_folds,\n",
    "                allow_incomplete_fold = allow_incomplete_fold,\n",
    "                return_all_indexes    = False,\n",
    "                differentiation       = differentiation,\n",
    "                verbose               = verbose\n",
    "                forecaster.window_size_diff\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load your data\n",
    "url = 'https://raw.githubusercontent.com/JoaquinAmatRodrigo/skforecast/master/data/h2o.csv'\n",
    "data = pd.read_csv(url, sep=',', header=0, names=['y', 'datetime'])\n",
    "data['datetime'] = pd.to_datetime(data['datetime'], format='%Y-%m-%d')\n",
    "data = data.set_index('datetime')\n",
    "data = data.asfreq('MS')\n",
    "data = data[['y']]\n",
    "\n",
    "# Split data into training and backtesting sets\n",
    "n_backtest = 36 * 3  # Last 9 years for backtesting\n",
    "data_train = data[:-n_backtest]\n",
    "data_backtest = data[-n_backtest:]\n",
    "\n",
    "# Initialize the forecaster\n",
    "forecaster = ForecasterAutoreg(\n",
    "    regressor=RandomForestRegressor(random_state=123),\n",
    "    lags=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 108\n",
      "    Number of folds: 11\n",
      "    Number of steps per fold: 10\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "    Last fold only includes 8 observations.\n",
      "\n",
      "Fold: 0\n",
      "    Training:   1991-07-01 00:00:00 -- 1999-06-01 00:00:00  (n=96)\n",
      "    Validation: 1999-07-01 00:00:00 -- 2000-04-01 00:00:00  (n=10)\n",
      "Fold: 1\n",
      "    Training:   1992-05-01 00:00:00 -- 2000-04-01 00:00:00  (n=96)\n",
      "    Validation: 2000-05-01 00:00:00 -- 2001-02-01 00:00:00  (n=10)\n",
      "Fold: 2\n",
      "    Training:   1993-03-01 00:00:00 -- 2001-02-01 00:00:00  (n=96)\n",
      "    Validation: 2001-03-01 00:00:00 -- 2001-12-01 00:00:00  (n=10)\n",
      "Fold: 3\n",
      "    Training:   1994-01-01 00:00:00 -- 2001-12-01 00:00:00  (n=96)\n",
      "    Validation: 2002-01-01 00:00:00 -- 2002-10-01 00:00:00  (n=10)\n",
      "Fold: 4\n",
      "    Training:   1994-11-01 00:00:00 -- 2002-10-01 00:00:00  (n=96)\n",
      "    Validation: 2002-11-01 00:00:00 -- 2003-08-01 00:00:00  (n=10)\n",
      "Fold: 5\n",
      "    Training:   1995-09-01 00:00:00 -- 2003-08-01 00:00:00  (n=96)\n",
      "    Validation: 2003-09-01 00:00:00 -- 2004-06-01 00:00:00  (n=10)\n",
      "Fold: 6\n",
      "    Training:   1996-07-01 00:00:00 -- 2004-06-01 00:00:00  (n=96)\n",
      "    Validation: 2004-07-01 00:00:00 -- 2005-04-01 00:00:00  (n=10)\n",
      "Fold: 7\n",
      "    Training:   1997-05-01 00:00:00 -- 2005-04-01 00:00:00  (n=96)\n",
      "    Validation: 2005-05-01 00:00:00 -- 2006-02-01 00:00:00  (n=10)\n",
      "Fold: 8\n",
      "    Training:   1998-03-01 00:00:00 -- 2006-02-01 00:00:00  (n=96)\n",
      "    Validation: 2006-03-01 00:00:00 -- 2006-12-01 00:00:00  (n=10)\n",
      "Fold: 9\n",
      "    Training:   1999-01-01 00:00:00 -- 2006-12-01 00:00:00  (n=96)\n",
      "    Validation: 2007-01-01 00:00:00 -- 2007-10-01 00:00:00  (n=10)\n",
      "Fold: 10\n",
      "    Training:   1999-11-01 00:00:00 -- 2007-10-01 00:00:00  (n=96)\n",
      "    Validation: 2007-11-01 00:00:00 -- 2008-06-01 00:00:00  (n=8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skforecast.model_selection import _create_backtesting_folds\n",
    "\n",
    "backtesting_folds = _create_backtesting_folds(\n",
    "    data =data['y'],\n",
    "    initial_train_size=len(data_train),\n",
    "    refit=True,\n",
    "    test_size= 10,\n",
    "    window_size=forecaster.window_size_diff,\n",
    "\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 96]</td>\n",
       "      <td>[96, 106]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10, 106]</td>\n",
       "      <td>[106, 116]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20, 116]</td>\n",
       "      <td>[116, 126]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[30, 126]</td>\n",
       "      <td>[126, 136]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40, 136]</td>\n",
       "      <td>[136, 146]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[50, 146]</td>\n",
       "      <td>[146, 156]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[60, 156]</td>\n",
       "      <td>[156, 166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[70, 166]</td>\n",
       "      <td>[166, 176]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[80, 176]</td>\n",
       "      <td>[176, 186]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[90, 186]</td>\n",
       "      <td>[186, 196]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[100, 196]</td>\n",
       "      <td>[196, 204]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0           1\n",
       "0      [0, 96]   [96, 106]\n",
       "1    [10, 106]  [106, 116]\n",
       "2    [20, 116]  [116, 126]\n",
       "3    [30, 126]  [126, 136]\n",
       "4    [40, 136]  [136, 146]\n",
       "5    [50, 146]  [146, 156]\n",
       "6    [60, 156]  [156, 166]\n",
       "7    [70, 166]  [166, 176]\n",
       "8    [80, 176]  [176, 186]\n",
       "9    [90, 186]  [186, 196]\n",
       "10  [100, 196]  [196, 204]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[n[0], n[3]] for n in backtesting_folds]) \n",
    "\n",
    "index_to_suffix_dict = {0 : \"_start\",\n",
    "                        1 : \"_end\"}\n",
    "\n",
    "\n",
    "def map_training_validation_indexes(df: pd.DataFrame, index_to_suffix_dict: dict) -> pd.DataFrame:\n",
    "    df = pd.concat([pd.DataFrame\n",
    "                        (df[index].to_list(), \n",
    "                            columns=['training'  + index_to_suffix_dict[index],\n",
    "                                     'validation'+ index_to_suffix_dict[index]]) \\\n",
    "                                     for index in index_to_suffix_dict], axis = 1)\n",
    "    return df\n",
    "\n",
    "def readjust_end_indexes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df[[\"training_end\", \"validation_end\"]] = df[[\"training_end\", \"validation_end\"]].apply(lambda x : (x - 1))\n",
    "    return df\n",
    "\n",
    "df_train_val_index_transformed = (df.pipe(map_training_validation_indexes, index_to_suffix_dict)\n",
    "                                  .pipe(readjust_end_indexes))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_validation_folds(df: pd.DataFrame, df_input: pd.DataFrame, df_pred: pd.DataFrame, folds_type: str)-> list:\n",
    "    columns = df.filter(regex = folds_type).columns\n",
    "    column_start, column_end = [col for col in columns if \"start\" in col], [col for col in columns if \"end\" in col]\n",
    "    folds_list = []\n",
    "    for fold in df.index:\n",
    "        validation_start = df[column_start].loc[fold].values[0]\n",
    "        validation_end   = df[column_end].loc[fold].values[0]\n",
    "        df_input_ = df_input.iloc[validation_start:validation_end]\n",
    "        date_index = df_input_.index\n",
    "        df_pred_ = df_pred.loc[date_index]\n",
    "        validation_fold = pd.concat([df_input_, df_pred_], axis = 1)\n",
    "        folds_list.append(validation_fold)\n",
    "    return folds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds_list_fin = get_training_validation_folds(df = df_train_val_index_transformed,\n",
    "                              df_input = data,\n",
    "                              df_pred= predictions_backtest,\n",
    "                              folds_type= \"validation\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[146], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cwd \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n\u001b[0;32m      2\u001b[0m backtest_result_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(cwd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/backtest_result.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m backtest_result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(backtest_result_file_path, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "cwd = os.path.dirname(__file__)\n",
    "backtest_result_file_path = os.path.join(cwd, '../data/backtest_result.csv')\n",
    "backtest_result_df = pd.read_csv(backtest_result_file_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
